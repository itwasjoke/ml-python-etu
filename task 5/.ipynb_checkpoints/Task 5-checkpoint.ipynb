{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97c0e41-d892-4897-a681-d7c886d2e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "491df38d-3ee8-4b2f-a557-b37afb5ced99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "student_results = pd.read_csv('jamb_exam_results.csv')\n",
    "\n",
    "# Приводим имена столбцов к нижнему регистру и заменяем пробелы на подчеркивания\n",
    "student_results.columns = student_results.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Удаляем столбец student_id\n",
    "student_results = student_results.drop(columns=['student_id'])\n",
    "\n",
    "# Заполняем пропущенные значения нулями\n",
    "student_results = student_results.fillna(0)\n",
    "\n",
    "# Разделяем данные на признаки (X) и целевую переменную (y)\n",
    "features = student_results.drop(columns=['jamb_score'])\n",
    "target = student_results['jamb_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "289ec0ba-03f9-498c-b68a-9f34e1d9af44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature used for the first split: study_hours_per_week\n"
     ]
    }
   ],
   "source": [
    "# Разбиваем данные на обучающую, валидационную и тестовую выборки\n",
    "train_features, temp_features, train_target, temp_target = train_test_split(features, target, test_size=0.4, random_state=42)\n",
    "val_features, test_features, val_target, test_target = train_test_split(temp_features, temp_target, test_size=0.5, random_state=42)\n",
    "\n",
    "# Преобразуем данные с помощью DictVectorizer\n",
    "converter = DictVectorizer(sparse=True)\n",
    "train_features_converted = converter.fit_transform(train_features.to_dict(orient='records'))\n",
    "val_features_converted = converter.transform(val_features.to_dict(orient='records'))\n",
    "test_features_converted = converter.transform(test_features.to_dict(orient='records'))\n",
    "\n",
    "# Обучаем модель дерева решений\n",
    "decision_tree = DecisionTreeRegressor(max_depth=1, random_state=42)\n",
    "decision_tree.fit(train_features_converted, train_target)\n",
    "\n",
    "# Находим признак, использованный для первого разбиения\n",
    "first_split_attribute = converter.feature_names_[decision_tree.tree_.feature[0]]\n",
    "print(f\"Feature used for the first split: {first_split_attribute}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cb4e316-d499-4f1b-85a5-9f42043840fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 42.173933892868\n"
     ]
    }
   ],
   "source": [
    "# Обучаем модель случайного леса\n",
    "forest = RandomForestRegressor(n_estimators=10, random_state=42, n_jobs=-1)\n",
    "forest.fit(train_features_converted, train_target)\n",
    "\n",
    "# Оцениваем модель на валидационных данных\n",
    "val_predictions = forest.predict(val_features_converted)\n",
    "val_rmse = np.sqrt(mean_squared_error(val_target, val_predictions))\n",
    "print(f\"Validation RMSE: {val_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd32719-d8b7-4f0f-b0a4-ae2cce138236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10, RMSE: 42.174\n",
      "n_estimators: 20, RMSE: 41.528\n",
      "n_estimators: 30, RMSE: 41.551\n",
      "n_estimators: 40, RMSE: 41.509\n",
      "n_estimators: 50, RMSE: 41.309\n",
      "n_estimators: 60, RMSE: 41.225\n",
      "n_estimators: 70, RMSE: 41.132\n",
      "n_estimators: 80, RMSE: 41.091\n",
      "n_estimators: 90, RMSE: 41.010\n",
      "n_estimators: 100, RMSE: 41.087\n",
      "n_estimators: 110, RMSE: 41.094\n",
      "n_estimators: 120, RMSE: 41.047\n",
      "n_estimators: 130, RMSE: 40.974\n",
      "n_estimators: 140, RMSE: 40.981\n",
      "n_estimators: 150, RMSE: 40.961\n",
      "n_estimators: 160, RMSE: 40.957\n",
      "n_estimators: 170, RMSE: 40.933\n",
      "n_estimators: 180, RMSE: 40.927\n",
      "n_estimators: 190, RMSE: 40.911\n",
      "n_estimators: 200, RMSE: 40.910\n",
      "Best max_depth: 10\n"
     ]
    }
   ],
   "source": [
    "# Поиск оптимального количества деревьев\n",
    "rmse_data = {}\n",
    "for num_trees in range(10, 201, 10):\n",
    "    forest = RandomForestRegressor(n_estimators=num_trees, random_state=42, n_jobs=-1)\n",
    "    forest.fit(train_features_converted, train_target)\n",
    "    val_predictions = forest.predict(val_features_converted)\n",
    "    rmse_data[num_trees] = np.sqrt(mean_squared_error(val_target, val_predictions))\n",
    "\n",
    "# Выводим результаты по количеству деревьев\n",
    "for num_trees, rmse_score in rmse_data.items():\n",
    "    print(f\"n_estimators: {num_trees}, RMSE: {rmse_score:.3f}\")\n",
    "\n",
    "\n",
    "# Находим лучшее значение max_depth\n",
    "depth_options = [10, 15, 20, 25]\n",
    "depth_results = {}\n",
    "\n",
    "for max_depth in depth_options:\n",
    "    rmse_scores = []\n",
    "    for num_trees in range(10, 201, 10):\n",
    "        forest = RandomForestRegressor(n_estimators=num_trees, max_depth=max_depth, random_state=42, n_jobs=-1)\n",
    "        forest.fit(train_features_converted, train_target)\n",
    "        val_predictions = forest.predict(val_features_converted)\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(val_target, val_predictions)))\n",
    "    depth_results[max_depth] = np.mean(rmse_scores)\n",
    "\n",
    "# Находим значение max_depth с минимальным средним RMSE\n",
    "optimal_depth = min(depth_results, key=depth_results.get)\n",
    "print(f\"Best max_depth: {optimal_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a546126d-56bb-4118-b3cc-3ef048ba74a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important feature: study_hours_per_week\n"
     ]
    }
   ],
   "source": [
    "# Обучаем финальную модель случайного леса\n",
    "best_forest = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=42, n_jobs=-1)\n",
    "best_forest.fit(train_features_converted, train_target)\n",
    "\n",
    "# Определяем в# Создание DMatrix для XGBoost\n",
    "boost_train = xgb.DMatrix(train_features_converted, label=train_target)\n",
    "boost_val = xgb.DMatrix(val_features_converted, label=val_target)\n",
    "\n",
    "# Создаем watchlist\n",
    "evaluation = [(boost_train, 'train'), (boost_val, 'eval')]\n",
    "\n",
    "# Параметры для XGBoost модели\n",
    "boost_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 42,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "# Обучение XGBoost с eta = 0.3\n",
    "boost_model_03 = xgb.train(boost_params, boost_train, num_boost_round=100, evals=evaluation, early_stopping_rounds=10)\n",
    "\n",
    "# Изменяем eta на 0.1 и повторяем обучение\n",
    "boost_params['eta'] = 0.1\n",
    "boost_model_01 = xgb.train(boost_params, boost_train, num_boost_round=100, evals=evaluation, early_stopping_rounds=10)\n",
    "\n",
    "# Выводим RMSE\n",
    "print(f\"Best validation RMSE with eta=0.3: {boost_model_03.best_score}\")\n",
    "print(f\"Best validation RMSE with eta=0.1: {boost_model_01.best_score}\")ажность признаков\n",
    "attribute_importances = best_forest.feature_importances_\n",
    "top_attribute = converter.feature_names_[np.argmax(attribute_importances)]\n",
    "print(f\"Most important feature: {top_attribute}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef4a81f7-baa5-49f1-bff5-a363e629823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:42.71579\teval-rmse:45.17452\n",
      "[1]\ttrain-rmse:39.82920\teval-rmse:43.33307\n",
      "[2]\ttrain-rmse:37.76334\teval-rmse:42.21338\n",
      "[3]\ttrain-rmse:36.28364\teval-rmse:41.85801\n",
      "[4]\ttrain-rmse:35.07326\teval-rmse:41.33436\n",
      "[5]\ttrain-rmse:34.19555\teval-rmse:41.08693\n",
      "[6]\ttrain-rmse:33.44294\teval-rmse:40.91599\n",
      "[7]\ttrain-rmse:32.67600\teval-rmse:40.88081\n",
      "[8]\ttrain-rmse:32.01974\teval-rmse:40.97827\n",
      "[9]\ttrain-rmse:31.53993\teval-rmse:40.88101\n",
      "[10]\ttrain-rmse:31.06525\teval-rmse:40.93403\n",
      "[11]\ttrain-rmse:30.73302\teval-rmse:40.99632\n",
      "[12]\ttrain-rmse:30.37063\teval-rmse:40.99476\n",
      "[13]\ttrain-rmse:29.88920\teval-rmse:41.01079\n",
      "[14]\ttrain-rmse:29.51041\teval-rmse:40.97999\n",
      "[15]\ttrain-rmse:29.18156\teval-rmse:41.04403\n",
      "[16]\ttrain-rmse:29.07860\teval-rmse:41.05910\n",
      "[0]\ttrain-rmse:45.50472\teval-rmse:47.29604\n",
      "[1]\ttrain-rmse:44.14512\teval-rmse:46.35598\n",
      "[2]\ttrain-rmse:42.95150\teval-rmse:45.45687\n",
      "[3]\ttrain-rmse:41.89408\teval-rmse:44.71852\n",
      "[4]\ttrain-rmse:40.93352\teval-rmse:44.07986\n",
      "[5]\ttrain-rmse:40.08378\teval-rmse:43.54894\n",
      "[6]\ttrain-rmse:39.29609\teval-rmse:43.13962\n",
      "[7]\ttrain-rmse:38.62620\teval-rmse:42.72406\n",
      "[8]\ttrain-rmse:37.99421\teval-rmse:42.38822\n",
      "[9]\ttrain-rmse:37.45821\teval-rmse:42.15136\n",
      "[10]\ttrain-rmse:36.87961\teval-rmse:41.89065\n",
      "[11]\ttrain-rmse:36.39186\teval-rmse:41.67045\n",
      "[12]\ttrain-rmse:35.97654\teval-rmse:41.48827\n",
      "[13]\ttrain-rmse:35.58356\teval-rmse:41.32783\n",
      "[14]\ttrain-rmse:35.19909\teval-rmse:41.19746\n",
      "[15]\ttrain-rmse:34.87280\teval-rmse:41.08102\n",
      "[16]\ttrain-rmse:34.49419\teval-rmse:41.02036\n",
      "[17]\ttrain-rmse:34.21047\teval-rmse:40.89152\n",
      "[18]\ttrain-rmse:33.86161\teval-rmse:40.81693\n",
      "[19]\ttrain-rmse:33.54623\teval-rmse:40.73449\n",
      "[20]\ttrain-rmse:33.31510\teval-rmse:40.62967\n",
      "[21]\ttrain-rmse:33.01815\teval-rmse:40.56287\n",
      "[22]\ttrain-rmse:32.72530\teval-rmse:40.44240\n",
      "[23]\ttrain-rmse:32.46554\teval-rmse:40.35823\n",
      "[24]\ttrain-rmse:32.27873\teval-rmse:40.34864\n",
      "[25]\ttrain-rmse:32.07275\teval-rmse:40.36024\n",
      "[26]\ttrain-rmse:31.84770\teval-rmse:40.34598\n",
      "[27]\ttrain-rmse:31.70331\teval-rmse:40.31013\n",
      "[28]\ttrain-rmse:31.55008\teval-rmse:40.34050\n",
      "[29]\ttrain-rmse:31.31432\teval-rmse:40.30854\n",
      "[30]\ttrain-rmse:31.14972\teval-rmse:40.30434\n",
      "[31]\ttrain-rmse:30.96455\teval-rmse:40.30561\n",
      "[32]\ttrain-rmse:30.84593\teval-rmse:40.30932\n",
      "[33]\ttrain-rmse:30.72308\teval-rmse:40.34924\n",
      "[34]\ttrain-rmse:30.59862\teval-rmse:40.33594\n",
      "[35]\ttrain-rmse:30.43686\teval-rmse:40.33099\n",
      "[36]\ttrain-rmse:30.33245\teval-rmse:40.29762\n",
      "[37]\ttrain-rmse:30.18239\teval-rmse:40.33330\n",
      "[38]\ttrain-rmse:30.05187\teval-rmse:40.32002\n",
      "[39]\ttrain-rmse:29.88769\teval-rmse:40.32972\n",
      "[40]\ttrain-rmse:29.75339\teval-rmse:40.34718\n",
      "[41]\ttrain-rmse:29.65207\teval-rmse:40.33684\n",
      "[42]\ttrain-rmse:29.51012\teval-rmse:40.34896\n",
      "[43]\ttrain-rmse:29.36722\teval-rmse:40.38274\n",
      "[44]\ttrain-rmse:29.19285\teval-rmse:40.36011\n",
      "[45]\ttrain-rmse:29.05923\teval-rmse:40.38301\n",
      "Best validation RMSE with eta=0.3: 40.88080588164972\n",
      "Best validation RMSE with eta=0.1: 40.29761755584483\n"
     ]
    }
   ],
   "source": [
    "# Создание DMatrix для XGBoost\n",
    "boost_train = xgb.DMatrix(train_features_converted, label=train_target)\n",
    "boost_val = xgb.DMatrix(val_features_converted, label=val_target)\n",
    "\n",
    "# Создаем watchlist\n",
    "evaluation = [(boost_train, 'train'), (boost_val, 'eval')]\n",
    "\n",
    "# Параметры для XGBoost модели\n",
    "boost_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 42,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "# Обучение XGBoost с eta = 0.3\n",
    "boost_model_03 = xgb.train(boost_params, boost_train, num_boost_round=100, evals=evaluation, early_stopping_rounds=10)\n",
    "\n",
    "# Изменяем eta на 0.1 и повторяем обучение\n",
    "boost_params['eta'] = 0.1\n",
    "boost_model_01 = xgb.train(boost_params, boost_train, num_boost_round=100, evals=evaluation, early_stopping_rounds=10)\n",
    "\n",
    "# Выводим RMSE\n",
    "print(f\"Best validation RMSE with eta=0.3: {boost_model_03.best_score}\")\n",
    "print(f\"Best validation RMSE with eta=0.1: {boost_model_01.best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70c18f-cf1b-4b49-bb8c-ab6c8ab51e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
